# Reflection on My Coding Experience

Completing this project was the first time I have ever accessed a dataset that is the magnitude of the Liberia 2019-20 DHS. It felt daunting at first to even download and read the data into R, where I cleaned it and created a dataset specifically for this project. Learning the different variables that are in the DHS datasets was a beneficial learning process, as it will make future DHS data analysis much faster. After clearing the data and creating a csv file, I was able to read the data into Pycharm. Once I did this, I realized I needed to modify the dataset more to only focus on age, gender, highest level of education, wealth index, and wealth index score. My original modified dataset included a few additional variables that I can use in future investigations, but weren't relevant to this specific project. I also had to clean the data a bit more in order to remove errors in the data that I wasn't able to see in R. Since the variable " Highest Level of Education‚Äù is a categorical variable, with the numbers 1-3 representing the level of education, I knew that I needed to use a classification method. I chose to use a supervised learning technique since, for this project I have thetargets already and am attempting to see whether a classification method world work. In addition, in the future, the classification be completely unsupervised since it is already known that there will be 4 groups to classify the data into.

The original goal of this part of my research was to create a model that could actually predict education levels, but due to time constraints, I decided to focus on testing which classification method would be best to use for future investigations to predict education levels. To begin, I used K nearest neighbors as the classification method. I tested a range of k and then found the maximum training and testing score. This part of the process surprised me by how long it took to run the code. I know ahead of time that it wouldn't be incredibly fast since I was also using K-fold to minimize the risk of my training and testing splits being biased. However, each test took an hour or more to run, even with a relatively small range of k values. I ended up testing with KNN 6 times. One time with the original data and once with scaled data. I also tested data scaled and unsealed. Finally, I used t- SNE to dimensionally reduce the data and I tested this once again with the scaled and unscaled data. Of all of these tests, the original data, with no dimensionally reduction, performed the best. The model was not overfit and classified 63.29% of the data correctly. It is important to note that, for each of the tests I also tested the KNN with distance weighting, but all of these tests ended up being very overfit with the testing score being close to 100% while the training score was between 50-60% for each of the tests.

After using KNN, I tested logistic regression. While these ran much faster, they were not as accurate, with scores between 0.4 and 0.5. There is a benefit to much faster classification, but this is a significant reduction in accuracy, meaning it would still be better to use KNN. I also completed 6 tests with logistic regression, using scaled and unscaled data with data before dimensionally reduction and then after using both PCA t-sNE.

Finally, I tested decision trees. These were relatively fast to run as well. However, after I tested a range for the depth of the tree, I still had to look at a graph to see the optimal d value. The accuracy scores for these tests averaged around 0.6, but were not as high as the KNN test with the original, unscaled data. Once again, I ran all 6 tests for this classification method.

It was important for this investigation to use a classification method since I had access to the targets and wanted to see whether be it would possible to ever predict education using these variables. In the future it would also be beneficial to test categorization methods to see if similar predictions can be made high, it would still give organizations on idea of how many people don't have an education, or what level of education they have, based on age, gender, and wealth. This process could also be replicated to predict any of these variables as well.

Overall, this process took me out of my comfort zone with coding and was a beneficial first look into how to access and use DHS data. More parameters should be tested in the future to ensure that the classification methods are maximized.
